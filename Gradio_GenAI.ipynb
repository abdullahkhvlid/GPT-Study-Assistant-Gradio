{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n7KFvPVPZOyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecac4236-70d9-46c3-e0de-1895c76edadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from gpt4all) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gpt4all) (4.67.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->gpt4all) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->gpt4all) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gpt4all\n",
            "Successfully installed gpt4all-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gpt4all gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ94m8aqZPj8",
        "outputId": "ae41b965-7f45-41c5-d440-9d660cc52ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.11G/4.11G [01:04<00:00, 63.6MiB/s]\n",
            "Verifying: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.11G/4.11G [00:07<00:00, 552MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text Samples with GPT4All:\n",
            "\n",
            "Sample 1 (Prompt: 'Once upon a time in a distant galaxy'):\n",
            ", there was a planet called Epsilon-4. The planet had been hit by a rogue asteroid that caused widespread destruction and devastation. Entire cities were flattened, and the survivors struggled to find food, shelter, and safety.\n",
            "\n",
            "But amidst all this chaos, there was one person who stood out - a young man named Kael. Kael was an orphan who had been living on the streets before the asteroid strike. He had always dreamed of\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 2 (Prompt: 'The future of artificial intelligence will'):\n",
            " be shaped by the way in which we teach machines to learn, reason and think. This involves developing new methods for creating and training intelligent systems that can adapt and evolve over time.\n",
            "\n",
            "One approach is to use a technique called reinforcement learning, which allows machines to learn from their own experiences by receiving feedback on their actions. For example, an AI system could be trained to play a game by receiving rewards or punishments based on its performance, allowing it to gradually improve over time.\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 3 (Prompt: 'In a small village near the mountains'):\n",
            ", there lived an old woman named Maria. She had spent her entire life tending to her animals and cultivating her garden. Despite her age, she was still sprightly and could often be seen working in her fields until well into the evening.\n",
            "\n",
            "One day, as Maria was walking back from the market with a basket full of fresh produce, she noticed that several of her goats were missing. She immediately suspected that one of her neighbors had taken them for their own use. Ang\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 4 (Prompt: 'The secret to happiness is'):\n",
            " simple: focus on what you have, not on what you don‚Äôt. It sounds easy enough, but it‚Äôs a lesson many of us struggle to learn. We‚Äôre constantly comparing ourselves to others and wishing for more ‚Äì more money, more possessions, more accolades. But the truth is that true happiness comes from within.\n",
            "\n",
            "When we take the time to appreciate the things we already have in our lives, we open ourselves up to a greater sense of contentment\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 5 (Prompt: 'When the clock struck midnight,'):\n",
            " I was still waiting for my Uber to arrive. I had ordered it half an hour ago but somehow it seemed like it would never come. As I sat on the edge of my bed and watched the seconds tick by, I couldn't help but feel a sense of frustration wash over me.\n",
            "\n",
            "I had planned this night out perfectly; I was going to meet some friends at a rooftop bar downtown for a drink or two before heading home. But now that plan seemed like it\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from gpt4all import GPT4All\n",
        "\n",
        "model = GPT4All(\"mistral-7b-instruct-v0.1.Q4_0.gguf\")\n",
        "\n",
        "prompts = [\n",
        "    \"Once upon a time in a distant galaxy\",\n",
        "    \"The future of artificial intelligence will\",\n",
        "    \"In a small village near the mountains\",\n",
        "    \"The secret to happiness is\",\n",
        "    \"When the clock struck midnight,\"\n",
        "]\n",
        "\n",
        "print(\"Generated Text Samples with GPT4All:\")\n",
        "for i, prompt in enumerate(prompts, 1):\n",
        "    print(f\"\\nSample {i} (Prompt: '{prompt}'):\")\n",
        "\n",
        "    response = model.generate(\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,\n",
        "        temp=0.7,\n",
        "        top_k=40,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    print(response)\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY4i6sAlZPlW",
        "outputId": "67592102-1ba7-4830-bcb8-ad6b9429aff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating text with different parameters (simulating 'epochs'):\n",
            "============================================================\n",
            "\n",
            "Generation 1 (like epoch 1):\n",
            "Prompt: 'The future of technology'\n",
            "Generated:  is constantly evolving and changing, but one thing that remains certain is the importance of innovation. Innovation drives progress and helps shape our world into a better place. In this article, we will explore some of the latest innovations in technology and how they are shaping our future.\n",
            "\n",
            "1. Artificial Intelligence (AI) and Machine Learning (ML) - AI and ML have been making waves in the tech industry for years now. These technologies allow machines to learn from data and make decisions without human intervention. They have numerous applications, including healthcare, finance, and transportation. AI and ML are helping us automate mundane tasks, diagnose diseases, detect fraud, and improve traffic flow.\n",
            "2. 5G Networks\n",
            "----------------------------------------\n",
            "\n",
            "Generation 2 (like epoch 2):\n",
            "Prompt: 'The future of technology'\n",
            "Generated:  is constantly evolving, and the world of cryptocurrencies is no exception. With new innovations emerging all the time, it can be challenging to keep up with the latest developments in this rapidly changing field. However, one thing that is certain is that the use of blockchain technology will continue to grow and play an increasingly important role in the world of finance.\n",
            "\n",
            "Blockchain technology is a decentralized digital ledger system that allows for secure and transparent transactions without the need for intermediaries such as banks or governments. It was originally developed for the cryptocurrency Bitcoin, but its potential applications go far beyond this. In fact, many industries are already exploring how blockchain technology can be used to improve their operations and enhance security\n",
            "----------------------------------------\n",
            "\n",
            "Generation 3 (like epoch 3):\n",
            "Prompt: 'The future of technology'\n",
            "Generated:  is filled with exciting possibilities and innovations that will change the way we live, work, and interact. One such innovation is Artificial Intelligence (AI), which has already started to transform various industries, including healthcare, finance, and transportation.\n",
            "\n",
            "AI refers to a branch of computer science that focuses on building intelligent machines capable of performing tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. AI is being used in many ways to improve efficiency, accuracy, and productivity across various industries.\n",
            "\n",
            "In healthcare, AI-powered tools are being used to analyze medical images, identify diseases, and predict outcomes. AI algorithms can also help doctors develop personalized treatment plans based on a patient's\n",
            "----------------------------------------\n",
            "\n",
            "Generation 4 (like epoch 4):\n",
            "Prompt: 'The future of technology'\n",
            "Generated:  is a fascinating topic that many people are eager to discuss. As computers become more advanced and integrated into our daily lives, it's important to consider how they will shape the world in the coming years.\n",
            "\n",
            "One area where technology is likely to have a significant impact is healthcare. With advancements in medical technology, doctors and researchers are able to diagnose and treat diseases with greater accuracy and effectiveness than ever before. This includes everything from gene therapy to robotic surgery, which allows for more precise and minimally invasive procedures.\n",
            "\n",
            "Another area where technology will continue to play a major role is transportation. Self-driving cars are already being developed by companies like Tesla and Google, and they have the potential to revolutionize the\n",
            "----------------------------------------\n",
            "\n",
            "Generation 5 (like epoch 5):\n",
            "Prompt: 'The future of technology'\n",
            "Generated:  is undoubtedly in the cloud. Cloud computing has revolutionized the way businesses operate, enabling them to scale their operations without worrying about infrastructure costs or limitations. However, as more sensitive data moves into the cloud, security concerns become even more critical.\n",
            "\n",
            "Cloud security is a major concern for businesses and individuals alike, and it's important to understand the potential risks involved in using cloud services. Here are some of the top threats to consider:\n",
            "\n",
            "1. Data Breaches: Cloud data breaches occur when unauthorized users gain access to sensitive information stored in the cloud. These breaches can result in significant financial losses, reputational damage, and legal liabilities.\n",
            "2. Insider Threats: Insiders are employees or contract\n",
            "----------------------------------------\n",
            "\n",
            "Note: GPT4All doesn't support traditional fine-tuning\n",
            "but we can improve generations with better parameters.\n"
          ]
        }
      ],
      "source": [
        "from gpt4all import GPT4All\n",
        "\n",
        "model = GPT4All(\"mistral-7b-instruct-v0.1.Q4_0.gguf\")\n",
        "\n",
        "test_prompt = \"The future of technology\"\n",
        "\n",
        "print(\"Generating text with different parameters (simulating 'epochs'):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    print(f\"\\nGeneration {epoch} (like epoch {epoch}):\")\n",
        "\n",
        "    response = model.generate(\n",
        "        prompt=test_prompt,\n",
        "        max_tokens=150,\n",
        "        temp=0.5 + (epoch * 0.05),\n",
        "        top_k=40,\n",
        "        top_p=0.85,\n",
        "        repeat_penalty=1.1\n",
        "    )\n",
        "    print(f\"Prompt: '{test_prompt}'\")\n",
        "    print(f\"Generated: {response}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"\\nNote: GPT4All doesn't support traditional fine-tuning\")\n",
        "print(\"but we can improve generations with better parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nGuPiZxBZPn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaacf936-fe63-40ac-d592-d992abe9ef2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poetry Generation with GPT4All:\n",
            "============================================================\n",
            "\n",
            "Poem 1 (Prompt: 'Write a romantic poem about love:'):\n",
            "\n",
            "A flame that flickers in the night,\n",
            "An echo of two hearts taking flight.\n",
            "A dance of passion and delight,\n",
            "That burns with all its might.\n",
            "\n",
            "Love is like a rose so red,\n",
            "It fills our hearts and minds with dread.\n",
            "For it can sting and cut so deep,\n",
            "Yet we cannot help but leap.\n",
            "\n",
            "In every moment that we share,\n",
            "Our love grows stronger there.\n",
            "And though the world may try to tear us apart,\n",
            "We'll hold on tight and never depart.\n",
            "\n",
            "Together we will stand as one,\n",
            "Underneath the shining moon.\n",
            "For our love is like a beacon bright,\n",
            "Guiding us through life's endless night.\n",
            "--------------------------------------------------\n",
            "\n",
            "Poem 2 (Prompt: 'Create a nature poem about mountains:'):\n",
            "\n",
            "\n",
            "In the grandeur of majestic peaks,  \n",
            "The mountain‚Äôs beauty I do seek.  \n",
            "With snow-capped crowns that pierce the sky,  \n",
            "They stand in awe-inspiring glory high. \n",
            "\n",
            "Boulders and rocks, their tales to tell,  \n",
            "Of ancient times when giants dwelt.  \n",
            "The valleys wide, the rivers flow,  \n",
            "Eternal guardians watch below. \n",
            "\n",
            "Silent strength, these giants of the earth,  \n",
            " Their beauty unsurpassed on this planet‚Äôs worth.  \n",
            "A symphony of peaks and greenery,  \n",
            "An untouched world for all to see. \n",
            "\n",
            "The mountain whispers secrets sweet,  \n",
            "Of life, of love, of dreams replete.  \n",
            "In every crevice, in each stone,  \n",
            "A memory of nature‚Äôs own. \n",
            "\n",
            "Oh,\n",
            "--------------------------------------------------\n",
            "\n",
            "Poem 3 (Prompt: 'Write a short haiku about cherry blossoms:'):\n",
            "\n",
            "Pink petals fall softly,\n",
            "Nature‚Äôs fleeting artistry.\n",
            "--------------------------------------------------\n",
            "\n",
            "Poem 4 (Prompt: 'Compose a poem about loneliness:'):\n",
            "\n",
            "Loneliness, the emptiness within,\n",
            "The feeling that no one can win.\n",
            "It's like walking on a barren land,\n",
            "Surrounded by nothing but sand.\n",
            "It's like being lost at sea,\n",
            "With no way to ever be free.\n",
            "It's like standing alone in a room,\n",
            "No one there to ever come through the gloom.\n",
            "Loneliness, it can consume your soul,\n",
            "Leaving you feeling cold and whole.\n",
            "But know that with time and care,\n",
            "You can find love beyond compare.\n",
            "--------------------------------------------------\n",
            "\n",
            "Poem 5 (Prompt: 'Write a joyful poem about spring:'):\n",
            "\n",
            "A season of growth and delight,\n",
            "Where flowers bloom in the sunlight,\n",
            "And birds chirp with all their might.\n",
            "\n",
            "The world awakens from its slumber,\n",
            "As winter‚Äôs grip begins to loosen,\n",
            "The earth breathes a sigh of relief,\n",
            "As springtime brings new life to all creatures.\n",
            "\n",
            "Squirrels scamper through the trees,\n",
            "Chasing each other with such glee,\n",
            "While butterflies flutter about,\n",
            "Bringing color and beauty to every spot.\n",
            "\n",
            "The air is filled with sweet fragrance,\n",
            "As blossoms bloom in every orchard,\n",
            "And fields of green stretch as far as the eye can see,\n",
            "Underneath a clear blue sky so serene.\n",
            "\n",
            "Spring, oh spring, how you fill our hearts,\n",
            "With joy and hope that never departs,\n",
            "For with each new bud and sprout,\n",
            "We\n",
            "--------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Poems in Different Styles:\n",
            "============================================================\n",
            "\n",
            "Style: Sonnet\n",
            "Prompt: Write a sonnet about the moon:\n",
            "Poem:\n",
            "\n",
            "\n",
            "In night's dark canvas, you paint with light,\n",
            "A silver orb hanging in the sky.\n",
            "You guide lost souls and bathe the world in fright,\n",
            "Your gentle glow can never die.\n",
            "\n",
            "Through phases of change, your face does shift and fade,\n",
            "Yet constant is your presence there.\n",
            "As lovers gaze upon your glowing shade,\n",
            "They find their hearts forever bare.\n",
            "\n",
            "In dreams, I've danced beneath your soft spell,\n",
            "Your luminous beams guiding me through sleep.\n",
            "And waking up to see you stand so well,\n",
            "I feel a peace that truly means.\n",
            "\n",
            "Oh Moon, with all your beauty and might,\n",
            "You rule\n",
            "----------------------------------------\n",
            "\n",
            "Style: Limerick\n",
            "Prompt: Create a limerick about a cat:\n",
            "Poem:\n",
            "\n",
            "There once was a cat from the sea,\n",
            "Whose fur shone bright as could be.\n",
            "With eyes of great might,\n",
            "And claws that would frighten,\n",
            "He ruled o'er his feline kingdom with glee.\n",
            "----------------------------------------\n",
            "\n",
            "Style: Free Verse\n",
            "Prompt: Write a free verse poem about the ocean:\n",
            "Poem:\n",
            "\n",
            "\n",
            "Endless, boundless blue horizon,\n",
            "The ocean calls to me,\n",
            "Its depths a mystery,\n",
            "A realm of secrets yet untold.\n",
            "\n",
            "Waves crash upon the shore,\n",
            "A symphony of nature's power,\n",
            "Frothy white caps break,\n",
            "As I stand in awe.\n",
            "\n",
            "Beneath the surface lies a world unknown,\n",
            "Teeming with life and wonder,\n",
            "Creatures great and small,\n",
            "Swimming through the dark abyss.\n",
            "\n",
            "The ocean is vast and deep,\n",
            "A never-ending expanse of water,\n",
            "Its beauty beyond measure,\n",
            "An endless source of inspiration.\n",
            "----------------------------------------\n",
            "\n",
            "Style: Acrostic\n",
            "Prompt: Compose an acrostic poem for 'DREAM':\n",
            "Poem:\n",
            " Determination, Resilience, Enthusiasm, Ambition, Motivation.\n",
            "\n",
            "Determination - To reach my goals and never give up, even when things get tough.\n",
            "Resilience - The strength to bounce back from failures and setbacks with renewed vigor.\n",
            "Enthusiasm - A burning passion for life that fuels my every step towards success.\n",
            "Ambition - The drive to achieve more than what I have already accomplished.\n",
            "Motivation - The inner fire that pushes me forward, never allowing complacency to set in.\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from gpt4all import GPT4All\n",
        "\n",
        "model = GPT4All(\"mistral-7b-instruct-v0.1.Q4_0.gguf\")\n",
        "\n",
        "poetry_prompts = [\n",
        "    \"Write a romantic poem about love:\",\n",
        "    \"Create a nature poem about mountains:\",\n",
        "    \"Write a short haiku about cherry blossoms:\",\n",
        "    \"Compose a poem about loneliness:\",\n",
        "    \"Write a joyful poem about spring:\"\n",
        "]\n",
        "\n",
        "print(\"Poetry Generation with GPT4All:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, prompt in enumerate(poetry_prompts, 1):\n",
        "    print(f\"\\nPoem {i} (Prompt: '{prompt}'):\")\n",
        "\n",
        "    response = model.generate(\n",
        "        prompt=prompt,\n",
        "        max_tokens=200,\n",
        "        temp=0.8,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repeat_penalty=1.2\n",
        "    )\n",
        "    print(response)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Poems in Different Styles:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "styles = [\n",
        "    (\"Write a sonnet about the moon:\", \"Sonnet\"),\n",
        "    (\"Create a limerick about a cat:\", \"Limerick\"),\n",
        "    (\"Write a free verse poem about the ocean:\", \"Free Verse\"),\n",
        "    (\"Compose an acrostic poem for 'DREAM':\", \"Acrostic\")\n",
        "]\n",
        "\n",
        "for prompt, style in styles:\n",
        "    print(f\"\\nStyle: {style}\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "\n",
        "    response = model.generate(\n",
        "        prompt=prompt,\n",
        "        max_tokens=150,\n",
        "        temp=0.75,\n",
        "        top_k=45,\n",
        "        top_p=0.92\n",
        "    )\n",
        "    print(f\"Poem:\\n{response}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PLGUc37-ZVKu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f5afeea-43ec-43ed-a449-2444bfc124cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: gpt4all in /usr/local/lib/python3.12/dist-packages (2.8.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from gpt4all) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gpt4all) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->gpt4all) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->gpt4all) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Loading GPT4All model...\n",
            "Model loaded successfully!\n",
            "\n",
            "Launching Gradio interface...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2892358068.py:55: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(title=\"GPT4All Chatbot\", theme=gr.themes.Soft()) as demo:\n",
            "/tmp/ipython-input-2892358068.py:63: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chat_display = gr.Chatbot(\n",
            "/tmp/ipython-input-2892358068.py:63: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chat_display = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f168329f8f95cd7ff5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f168329f8f95cd7ff5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "!pip install gradio gpt4all\n",
        "\n",
        "import gradio as gr\n",
        "from gpt4all import GPT4All\n",
        "import threading\n",
        "\n",
        "print(\"Loading GPT4All model...\")\n",
        "model = GPT4All(\"mistral-7b-instruct-v0.1.Q4_0.gguf\")\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "class GPT4AllChatbot:\n",
        "    def __init__(self):\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def generate_response(self, prompt, max_tokens=150, temperature=0.7, top_p=0.9):\n",
        "        \"\"\"Generate response using GPT4All\"\"\"\n",
        "        try:\n",
        "            response = model.generate(\n",
        "                prompt=prompt,\n",
        "                max_tokens=max_tokens,\n",
        "                temp=temperature,\n",
        "                top_p=top_p,\n",
        "                top_k=40,\n",
        "                repeat_penalty=1.1\n",
        "            )\n",
        "            return response.strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "    def chat(self, message, history, max_tokens, temperature, top_p):\n",
        "        \"\"\"Handle chat conversation\"\"\"\n",
        "        if not message:\n",
        "            return \"\", history\n",
        "\n",
        "        context = \"\"\n",
        "        if history:\n",
        "            for user_msg, bot_msg in history[-3:]:\n",
        "                context += f\"User: {user_msg}\\nAssistant: {bot_msg}\\n\"\n",
        "\n",
        "        full_prompt = f\"{context}User: {message}\\nAssistant:\"\n",
        "\n",
        "        response = self.generate_response(\n",
        "            full_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p\n",
        "        )\n",
        "\n",
        "        history.append((message, response))\n",
        "\n",
        "        return \"\", history\n",
        "\n",
        "chatbot = GPT4AllChatbot()\n",
        "\n",
        "with gr.Blocks(title=\"GPT4All Chatbot\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    #  GPT4All Chatbot\n",
        "    ### Powered by Mistral 7B ¬∑ Running Locally\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            chat_display = gr.Chatbot(\n",
        "                label=\"Conversation\",\n",
        "                height=400,\n",
        "                avatar_images=(None, \"ü§ñ\")\n",
        "            )\n",
        "            chat_state = gr.State([])\n",
        "\n",
        "            with gr.Row():\n",
        "                user_input = gr.Textbox(\n",
        "                    label=\"Your Message\",\n",
        "                    placeholder=\"Type your message here...\",\n",
        "                    scale=4\n",
        "                )\n",
        "                send_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "            with gr.Row():\n",
        "                clear_btn = gr.Button(\"Clear Chat\")\n",
        "                generate_btn = gr.Button(\"Generate Poem\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"###  Settings\")\n",
        "\n",
        "            max_tokens = gr.Slider(\n",
        "                50, 500, 200,\n",
        "                step=10,\n",
        "                label=\"Response Length (tokens)\"\n",
        "            )\n",
        "\n",
        "            temperature = gr.Slider(\n",
        "                0.1, 1.5, 0.7,\n",
        "                step=0.1,\n",
        "                label=\"Temperature\"\n",
        "            )\n",
        "\n",
        "            top_p = gr.Slider(\n",
        "                0.1, 1.0, 0.9,\n",
        "                step=0.05,\n",
        "                label=\"Top-p\"\n",
        "            )\n",
        "\n",
        "            gr.Markdown(\"###  Quick Actions\")\n",
        "\n",
        "            with gr.Row():\n",
        "                gr.Button(\"Poem\", size=\"sm\").click(\n",
        "                    lambda: \"Write a short poem about nature\",\n",
        "                    outputs=user_input\n",
        "                )\n",
        "                gr.Button(\"Story\", size=\"sm\").click(\n",
        "                    lambda: \"Tell me a short story\",\n",
        "                    outputs=user_input\n",
        "                )\n",
        "\n",
        "            gr.Markdown(\"###  Examples\")\n",
        "            examples = gr.Examples(\n",
        "                examples=[\n",
        "                    [\"Explain quantum computing in simple terms\"],\n",
        "                    [\"Write a haiku about cherry blossoms\"],\n",
        "                    [\"What is the meaning of life?\"],\n",
        "                    [\"Tell me a joke about programmers\"]\n",
        "                ],\n",
        "                inputs=user_input\n",
        "            )\n",
        "\n",
        "    def process_message(message, history, max_tokens_val, temp_val, top_p_val):\n",
        "        if not message:\n",
        "            return \"\", history\n",
        "\n",
        "        response = chatbot.generate_response(\n",
        "            f\"User: {message}\\nAssistant:\",\n",
        "            max_tokens=max_tokens_val,\n",
        "            temperature=temp_val,\n",
        "            top_p=top_p_val\n",
        "        )\n",
        "\n",
        "        history.append((message, response))\n",
        "        return \"\", history\n",
        "\n",
        "    def generate_random_poem(history, max_tokens_val, temp_val, top_p_val):\n",
        "        prompts = [\n",
        "            \"Write a poem about love\",\n",
        "            \"Create a nature poem\",\n",
        "            \"Write about the stars\",\n",
        "            \"Compose a poem about hope\"\n",
        "        ]\n",
        "        import random\n",
        "        prompt = random.choice(prompts)\n",
        "\n",
        "        response = chatbot.generate_response(\n",
        "            prompt,\n",
        "            max_tokens=max_tokens_val,\n",
        "            temperature=temp_val,\n",
        "            top_p=top_p_val\n",
        "        )\n",
        "\n",
        "        history.append((prompt, response))\n",
        "        return \"\", history\n",
        "\n",
        "    def clear_history():\n",
        "        return []\n",
        "\n",
        "    # Event handlers\n",
        "    send_btn.click(\n",
        "        process_message,\n",
        "        inputs=[user_input, chat_state, max_tokens, temperature, top_p],\n",
        "        outputs=[user_input, chat_state]\n",
        "    ).then(\n",
        "        lambda x: x,\n",
        "        inputs=[chat_state],\n",
        "        outputs=[chat_display]\n",
        "    )\n",
        "\n",
        "    user_input.submit(\n",
        "        process_message,\n",
        "        inputs=[user_input, chat_state, max_tokens, temperature, top_p],\n",
        "        outputs=[user_input, chat_state]\n",
        "    ).then(\n",
        "        lambda x: x,\n",
        "        inputs=[chat_state],\n",
        "        outputs=[chat_display]\n",
        "    )\n",
        "\n",
        "    generate_btn.click(\n",
        "        generate_random_poem,\n",
        "        inputs=[chat_state, max_tokens, temperature, top_p],\n",
        "        outputs=[user_input, chat_state]\n",
        "    ).then(\n",
        "        lambda x: x,\n",
        "        inputs=[chat_state],\n",
        "        outputs=[chat_display]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        clear_history,\n",
        "        outputs=[chat_state]\n",
        "    ).then(\n",
        "        lambda: [],\n",
        "        outputs=[chat_display]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"\"\"\n",
        "    **Tips:**\n",
        "    - Higher temperature = more creative/random responses\n",
        "    - Lower temperature = more focused/predictable responses\n",
        "    - Top-p controls diversity (0.9 is good for balanced responses)\n",
        "    - Model: Mistral 7B (4-bit quantized)\n",
        "    \"\"\")\n",
        "\n",
        "print(\"\\nLaunching Gradio interface...\")\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}